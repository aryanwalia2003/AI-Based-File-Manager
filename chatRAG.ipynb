{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOHlAk3DGozN1FwTRWYjTfo"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install -q langchain_community"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GtEOKJqunKj8",
        "outputId": "2259d506-42e5-4f31-b1b6-3a5f08e9b96a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m22.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!!pip install -q langchain_openai faiss-cpu"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kblloRMdlcMd",
        "outputId": "864024cf-0668-49de-f702-ee4bb9cfa1da"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['\\x1b[?25l   \\x1b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m \\x1b[32m0.0/55.3 kB\\x1b[0m \\x1b[31m?\\x1b[0m eta \\x1b[36m-:--:--\\x1b[0m',\n",
              " '\\x1b[2K   \\x1b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m \\x1b[32m55.3/55.3 kB\\x1b[0m \\x1b[31m2.5 MB/s\\x1b[0m eta \\x1b[36m0:00:00\\x1b[0m',\n",
              " '\\x1b[?25h\\x1b[?25l   \\x1b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m \\x1b[32m0.0/30.7 MB\\x1b[0m \\x1b[31m?\\x1b[0m eta \\x1b[36m-:--:--\\x1b[0m',\n",
              " '\\x1b[2K   \\x1b[91m━\\x1b[0m\\x1b[90m╺\\x1b[0m\\x1b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m \\x1b[32m1.0/30.7 MB\\x1b[0m \\x1b[31m28.7 MB/s\\x1b[0m eta \\x1b[36m0:00:02\\x1b[0m',\n",
              " '\\x1b[2K   \\x1b[91m━\\x1b[0m\\x1b[91m╸\\x1b[0m\\x1b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m \\x1b[32m1.4/30.7 MB\\x1b[0m \\x1b[31m17.8 MB/s\\x1b[0m eta \\x1b[36m0:00:02\\x1b[0m',\n",
              " '\\x1b[2K   \\x1b[91m━━━\\x1b[0m\\x1b[90m╺\\x1b[0m\\x1b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m \\x1b[32m2.4/30.7 MB\\x1b[0m \\x1b[31m18.3 MB/s\\x1b[0m eta \\x1b[36m0:00:02\\x1b[0m',\n",
              " '\\x1b[2K   \\x1b[91m━━━━\\x1b[0m\\x1b[90m╺\\x1b[0m\\x1b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m \\x1b[32m3.3/30.7 MB\\x1b[0m \\x1b[31m18.6 MB/s\\x1b[0m eta \\x1b[36m0:00:02\\x1b[0m',\n",
              " '\\x1b[2K   \\x1b[91m━━━━━\\x1b[0m\\x1b[90m╺\\x1b[0m\\x1b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m \\x1b[32m4.1/30.7 MB\\x1b[0m \\x1b[31m19.2 MB/s\\x1b[0m eta \\x1b[36m0:00:02\\x1b[0m',\n",
              " '\\x1b[2K   \\x1b[91m━━━━━━━\\x1b[0m\\x1b[91m╸\\x1b[0m\\x1b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m \\x1b[32m5.8/30.7 MB\\x1b[0m \\x1b[31m22.0 MB/s\\x1b[0m eta \\x1b[36m0:00:02\\x1b[0m',\n",
              " '\\x1b[2K   \\x1b[91m━━━━━━━━━\\x1b[0m\\x1b[91m╸\\x1b[0m\\x1b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m \\x1b[32m7.5/30.7 MB\\x1b[0m \\x1b[31m24.8 MB/s\\x1b[0m eta \\x1b[36m0:00:01\\x1b[0m',\n",
              " '\\x1b[2K   \\x1b[91m━━━━━━━━━━━\\x1b[0m\\x1b[91m╸\\x1b[0m\\x1b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m \\x1b[32m9.1/30.7 MB\\x1b[0m \\x1b[31m26.8 MB/s\\x1b[0m eta \\x1b[36m0:00:01\\x1b[0m',\n",
              " '\\x1b[2K   \\x1b[91m━━━━━━━━━━━━━━\\x1b[0m\\x1b[90m╺\\x1b[0m\\x1b[90m━━━━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m \\x1b[32m11.0/30.7 MB\\x1b[0m \\x1b[31m29.6 MB/s\\x1b[0m eta \\x1b[36m0:00:01\\x1b[0m',\n",
              " '\\x1b[2K   \\x1b[91m━━━━━━━━━━━━━━\\x1b[0m\\x1b[91m╸\\x1b[0m\\x1b[90m━━━━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m \\x1b[32m11.4/30.7 MB\\x1b[0m \\x1b[31m28.6 MB/s\\x1b[0m eta \\x1b[36m0:00:01\\x1b[0m',\n",
              " '\\x1b[2K   \\x1b[91m━━━━━━━━━━━━━━━\\x1b[0m\\x1b[91m╸\\x1b[0m\\x1b[90m━━━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m \\x1b[32m12.2/30.7 MB\\x1b[0m \\x1b[31m29.8 MB/s\\x1b[0m eta \\x1b[36m0:00:01\\x1b[0m',\n",
              " '\\x1b[2K   \\x1b[91m━━━━━━━━━━━━━━━━━\\x1b[0m\\x1b[91m╸\\x1b[0m\\x1b[90m━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m \\x1b[32m13.5/30.7 MB\\x1b[0m \\x1b[31m33.1 MB/s\\x1b[0m eta \\x1b[36m0:00:01\\x1b[0m',\n",
              " '\\x1b[2K   \\x1b[91m━━━━━━━━━━━━━━━━━━━\\x1b[0m\\x1b[91m╸\\x1b[0m\\x1b[90m━━━━━━━━━━━━━━━━━━━━\\x1b[0m \\x1b[32m15.2/30.7 MB\\x1b[0m \\x1b[31m34.7 MB/s\\x1b[0m eta \\x1b[36m0:00:01\\x1b[0m',\n",
              " '\\x1b[2K   \\x1b[91m━━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m\\x1b[90m╺\\x1b[0m\\x1b[90m━━━━━━━━━━━━━━━━\\x1b[0m \\x1b[32m17.7/30.7 MB\\x1b[0m \\x1b[31m36.7 MB/s\\x1b[0m eta \\x1b[36m0:00:01\\x1b[0m',\n",
              " '\\x1b[2K   \\x1b[91m━━━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m\\x1b[91m╸\\x1b[0m\\x1b[90m━━━━━━━━━━━━━━━\\x1b[0m \\x1b[32m19.2/30.7 MB\\x1b[0m \\x1b[31m35.6 MB/s\\x1b[0m eta \\x1b[36m0:00:01\\x1b[0m',\n",
              " '\\x1b[2K   \\x1b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m\\x1b[91m╸\\x1b[0m\\x1b[90m━━━━━━━━━━━━━\\x1b[0m \\x1b[32m20.6/30.7 MB\\x1b[0m \\x1b[31m35.4 MB/s\\x1b[0m eta \\x1b[36m0:00:01\\x1b[0m',\n",
              " '\\x1b[2K   \\x1b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m\\x1b[90m╺\\x1b[0m\\x1b[90m━━━━━━━━━━\\x1b[0m \\x1b[32m22.4/30.7 MB\\x1b[0m \\x1b[31m43.0 MB/s\\x1b[0m eta \\x1b[36m0:00:01\\x1b[0m',\n",
              " '\\x1b[2K   \\x1b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m\\x1b[90m╺\\x1b[0m\\x1b[90m━━━━━━━━\\x1b[0m \\x1b[32m24.1/30.7 MB\\x1b[0m \\x1b[31m48.4 MB/s\\x1b[0m eta \\x1b[36m0:00:01\\x1b[0m',\n",
              " '\\x1b[2K   \\x1b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m\\x1b[91m╸\\x1b[0m\\x1b[90m━━━━━━\\x1b[0m \\x1b[32m25.7/30.7 MB\\x1b[0m \\x1b[31m47.2 MB/s\\x1b[0m eta \\x1b[36m0:00:01\\x1b[0m',\n",
              " '\\x1b[2K   \\x1b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m\\x1b[90m╺\\x1b[0m\\x1b[90m━━━━━\\x1b[0m \\x1b[32m26.4/30.7 MB\\x1b[0m \\x1b[31m42.1 MB/s\\x1b[0m eta \\x1b[36m0:00:01\\x1b[0m',\n",
              " '\\x1b[2K   \\x1b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m\\x1b[91m╸\\x1b[0m\\x1b[90m━━━━\\x1b[0m \\x1b[32m27.5/30.7 MB\\x1b[0m \\x1b[31m39.6 MB/s\\x1b[0m eta \\x1b[36m0:00:01\\x1b[0m',\n",
              " '\\x1b[2K   \\x1b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m\\x1b[91m╸\\x1b[0m\\x1b[90m━━━\\x1b[0m \\x1b[32m28.3/30.7 MB\\x1b[0m \\x1b[31m37.4 MB/s\\x1b[0m eta \\x1b[36m0:00:01\\x1b[0m',\n",
              " '\\x1b[2K   \\x1b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m\\x1b[91m╸\\x1b[0m\\x1b[90m━━\\x1b[0m \\x1b[32m29.1/30.7 MB\\x1b[0m \\x1b[31m34.4 MB/s\\x1b[0m eta \\x1b[36m0:00:01\\x1b[0m',\n",
              " '\\x1b[2K   \\x1b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m\\x1b[90m╺\\x1b[0m \\x1b[32m30.0/30.7 MB\\x1b[0m \\x1b[31m33.0 MB/s\\x1b[0m eta \\x1b[36m0:00:01\\x1b[0m',\n",
              " '\\x1b[2K   \\x1b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m\\x1b[91m╸\\x1b[0m \\x1b[32m30.7/30.7 MB\\x1b[0m \\x1b[31m31.5 MB/s\\x1b[0m eta \\x1b[36m0:00:01\\x1b[0m',\n",
              " '\\x1b[2K   \\x1b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m\\x1b[91m╸\\x1b[0m \\x1b[32m30.7/30.7 MB\\x1b[0m \\x1b[31m31.5 MB/s\\x1b[0m eta \\x1b[36m0:00:01\\x1b[0m',\n",
              " '\\x1b[2K   \\x1b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m\\x1b[91m╸\\x1b[0m \\x1b[32m30.7/30.7 MB\\x1b[0m \\x1b[31m31.5 MB/s\\x1b[0m eta \\x1b[36m0:00:01\\x1b[0m',\n",
              " '\\x1b[2K   \\x1b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m\\x1b[91m╸\\x1b[0m \\x1b[32m30.7/30.7 MB\\x1b[0m \\x1b[31m31.5 MB/s\\x1b[0m eta \\x1b[36m0:00:01\\x1b[0m',\n",
              " '\\x1b[2K   \\x1b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m\\x1b[91m╸\\x1b[0m \\x1b[32m30.7/30.7 MB\\x1b[0m \\x1b[31m31.5 MB/s\\x1b[0m eta \\x1b[36m0:00:01\\x1b[0m',\n",
              " '\\x1b[2K   \\x1b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m\\x1b[91m╸\\x1b[0m \\x1b[32m30.7/30.7 MB\\x1b[0m \\x1b[31m31.5 MB/s\\x1b[0m eta \\x1b[36m0:00:01\\x1b[0m',\n",
              " '\\x1b[2K   \\x1b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m\\x1b[91m╸\\x1b[0m \\x1b[32m30.7/30.7 MB\\x1b[0m \\x1b[31m31.5 MB/s\\x1b[0m eta \\x1b[36m0:00:01\\x1b[0m',\n",
              " '\\x1b[2K   \\x1b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m\\x1b[91m╸\\x1b[0m \\x1b[32m30.7/30.7 MB\\x1b[0m \\x1b[31m31.5 MB/s\\x1b[0m eta \\x1b[36m0:00:01\\x1b[0m',\n",
              " '\\x1b[2K   \\x1b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m\\x1b[91m╸\\x1b[0m \\x1b[32m30.7/30.7 MB\\x1b[0m \\x1b[31m31.5 MB/s\\x1b[0m eta \\x1b[36m0:00:01\\x1b[0m',\n",
              " '\\x1b[2K   \\x1b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m \\x1b[32m30.7/30.7 MB\\x1b[0m \\x1b[31m15.1 MB/s\\x1b[0m eta \\x1b[36m0:00:00\\x1b[0m',\n",
              " '\\x1b[?25h\\x1b[?25l   \\x1b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m \\x1b[32m0.0/1.2 MB\\x1b[0m \\x1b[31m?\\x1b[0m eta \\x1b[36m-:--:--\\x1b[0m',\n",
              " '\\x1b[2K   \\x1b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m\\x1b[91m╸\\x1b[0m \\x1b[32m1.2/1.2 MB\\x1b[0m \\x1b[31m54.5 MB/s\\x1b[0m eta \\x1b[36m0:00:01\\x1b[0m',\n",
              " '\\x1b[2K   \\x1b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m \\x1b[32m1.2/1.2 MB\\x1b[0m \\x1b[31m23.1 MB/s\\x1b[0m eta \\x1b[36m0:00:00\\x1b[0m',\n",
              " '\\x1b[?25h']"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_openai import AzureChatOpenAI\n",
        "from langchain.prompts import PromptTemplate\n",
        "from langchain.chains import LLMChain"
      ],
      "metadata": {
        "id": "1XMrGKGDl7Ki"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "api_key=userdata.get('openai_key')"
      ],
      "metadata": {
        "id": "c_mtZESYoo2O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "AZURE_API_KEY=userdata.get('AZURE_API_KEY')\n",
        "AZURE_ENDPOINT=userdata.get('AZURE_ENDPOINT')"
      ],
      "metadata": {
        "id": "cs9seZV32OI-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "llm = AzureChatOpenAI(\n",
        "    azure_endpoint=AZURE_ENDPOINT,\n",
        "    azure_deployment=\"gpt-4o\",\n",
        "    api_version=\"2023-09-01-preview\",\n",
        "    api_key=AZURE_API_KEY,\n",
        "    temperature=0.3\n",
        ")\n"
      ],
      "metadata": {
        "id": "7CZTYJfmlWzO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chat_models import AzureChatOpenAI\n",
        "from langchain.schema import AIMessage, HumanMessage, SystemMessage\n",
        "import json\n",
        "import time\n",
        "import random\n",
        "diseases = [\n",
        "    \"Diabetes Mellitus\", \"Hypertension\", \"Alzheimer's Disease\", \"Parkinson's Disease\",\n",
        "    \"Tuberculosis\", \"Pneumonia\", \"Influenza\"\n",
        "]\n",
        "all_conversations = []\n",
        "\n",
        "for disease in diseases:\n",
        "    agents = {\n",
        "        \"Dr. Smith\": f\"Dr. Smith is an experienced specialist in {disease}, explaining its symptoms, causes, and treatment options in detail.\",\n",
        "        \"Dr. Patel\": f\"Dr. Patel is an expert in treating and managing {disease}, focusing on long-term care, medications, and lifestyle changes.\",\n",
        "        \"Dr. Lee\": f\"Dr. Lee is a researcher specializing in {disease}, discussing the latest advancements, clinical trials, and future treatments.\",\n",
        "        \"James\": f\"James has been diagnosed with {disease}. He only asks detailed questions about symptoms, treatments, medications, and prognosis. He does not provide medical knowledge or commentary.\"\n",
        "    }\n",
        "\n",
        "    conversation_history = [\n",
        "        HumanMessage(content=f\"You have been diagnosed with {disease}. Start by asking the doctor specialised in treating {disease} basic questions about its symptoms and treatment options.\", name=\"System\")\n",
        "    ]\n",
        "\n",
        "\n",
        "    def generate_message(speaker, history):\n",
        "      sanitized_speaker = speaker.replace(\" \", \"_\").replace(\".\", \"\").lower()\n",
        "\n",
        "      system_prompt = (\n",
        "          f\"{agents[speaker]} Keep responses well-structured, factual, and educational. \"\n",
        "          f\"Maintain a natural, professional tone. Avoid overusing the listener's name unnecessarily, \"\n",
        "          f\"or repeating phrases like 'let’s continue,' 'sure,' or 'of course.' \"\n",
        "          f\"Answer directly and naturally, responding to the previous message without unnecessary transitions. \"\n",
        "          f\"If you are a specialist, always provide a complete answer without asking James what he wants to focus on. \"\n",
        "          f\"You are a top expert in {disease}, and your goal is to share your knowledge concisely and understandably. \"\n",
        "          f\"Your answers should be **max 80 words**, written in simple paragraphs (not bullet points). \"\n",
        "          f\"If you are James, your only role is to ask one specific, medically detailed question per turn. \"\n",
        "          f\"James **must not provide medical explanations**—he only asks patient-related questions. \"\n",
        "          f\"James must not ask doctors to clarify; instead, he must ask a direct follow-up question. \"\n",
        "          f\"For example, instead of saying 'Can you specify your question?' James should ask 'How does insulin resistance develop in diabetes?' or 'What are the risks of uncontrolled hypertension over time?'\"\n",
        "      )\n",
        "\n",
        "      print(f\"\\n🔍 DEBUG: Preparing request for {sanitized_speaker}...\")\n",
        "\n",
        "\n",
        "      start_time = time.time()\n",
        "      try:\n",
        "          print(f\"🔍 DEBUG: Sending request to Azure OpenAI for {sanitized_speaker}...\")\n",
        "\n",
        "          response = llm([\n",
        "              SystemMessage(content=system_prompt, name=\"system\"),\n",
        "              *[\n",
        "                  HumanMessage(content=msg.content, name=msg.name.replace(\" \", \"_\").replace(\".\", \"\").lower())\n",
        "                  if isinstance(msg, HumanMessage)\n",
        "                  else AIMessage(content=msg.content, name=msg.name.replace(\" \", \"_\").replace(\".\", \"\").lower())\n",
        "                  for msg in history[-random.randint(3, 7):]\n",
        "              ],\n",
        "              HumanMessage(content=\"Continue the conversation.\", name=\"james\")\n",
        "          ])\n",
        "\n",
        "          response_time = time.time() - start_time\n",
        "\n",
        "          print(f\"✅ DEBUG: {sanitized_speaker} responded in {response_time:.2f} seconds\")\n",
        "          print(f\"📝 RESPONSE: {response.content[:100]}...\\n\")\n",
        "\n",
        "          return AIMessage(content=response.content, name=sanitized_speaker)\n",
        "\n",
        "      except Exception as e:\n",
        "          print(f\"❌ ERROR: Failed to generate message for {sanitized_speaker}\")\n",
        "          print(str(e))\n",
        "          return AIMessage(content=\"(Error: No response from LLM)\", name=sanitized_speaker)\n",
        "\n",
        "\n",
        "    num_messages = 25\n",
        "    generated_messages = 0\n",
        "\n",
        "    for i in range(num_messages):\n",
        "        if i % 2 == 0:\n",
        "            current_speaker = \"James\"\n",
        "        else:\n",
        "            current_speaker = random.choice([\"Dr. Smith\", \"Dr. Patel\", \"Dr. Lee\"])\n",
        "\n",
        "        new_message = generate_message(current_speaker, conversation_history)\n",
        "        conversation_history.append(new_message)\n",
        "        generated_messages += 1\n",
        "\n",
        "        if generated_messages % 10 == 0:\n",
        "            print(f\"✅ DEBUG: Generated {generated_messages}/{num_messages} messages for {disease}...\")\n",
        "\n",
        "        time.sleep(1)\n",
        "    all_conversations.append({\n",
        "        \"disease\": disease,\n",
        "        \"chat\": [\n",
        "            {\"timestamp\": time.strftime('%Y-%m-%d %H:%M:%S'), \"speaker\": msg.name, \"message\": msg.content}\n",
        "            for msg in conversation_history\n",
        "        ]\n",
        "    })\n",
        "\n",
        "\n",
        "with open(\"large_chat_dataset.json\", \"w\") as f:\n",
        "    json.dump(all_conversations, f, indent=4)\n",
        "\n",
        "print(\"\\n🎉 Large dataset saved to large_chat_dataset.json\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "yC600GB9UoHT",
        "outputId": "eccf80d7-a3a2-486a-fa85-c3e45c88d031"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "🔍 DEBUG: Preparing request for james...\n",
            "🔍 DEBUG: Sending request to Azure OpenAI for james...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-6-9f263b984aaf>:49: LangChainDeprecationWarning: The method `BaseChatModel.__call__` was deprecated in langchain-core 0.1.7 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
            "  response = llm([\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ DEBUG: james responded in 0.82 seconds\n",
            "📝 RESPONSE: What are the common symptoms of Diabetes Mellitus?...\n",
            "\n",
            "\n",
            "🔍 DEBUG: Preparing request for dr_lee...\n",
            "🔍 DEBUG: Sending request to Azure OpenAI for dr_lee...\n",
            "✅ DEBUG: dr_lee responded in 4.52 seconds\n",
            "📝 RESPONSE: Common symptoms of Diabetes Mellitus include increased thirst (polydipsia), frequent urination (poly...\n",
            "\n",
            "\n",
            "🔍 DEBUG: Preparing request for james...\n",
            "🔍 DEBUG: Sending request to Azure OpenAI for james...\n",
            "✅ DEBUG: james responded in 0.46 seconds\n",
            "📝 RESPONSE: What are the main treatment options for Diabetes Mellitus?...\n",
            "\n",
            "\n",
            "🔍 DEBUG: Preparing request for dr_patel...\n",
            "🔍 DEBUG: Sending request to Azure OpenAI for dr_patel...\n",
            "✅ DEBUG: dr_patel responded in 1.67 seconds\n",
            "📝 RESPONSE: The main treatment options for Diabetes Mellitus depend on the type. For Type 1 diabetes, insulin th...\n",
            "\n",
            "\n",
            "🔍 DEBUG: Preparing request for james...\n",
            "🔍 DEBUG: Sending request to Azure OpenAI for james...\n",
            "✅ DEBUG: james responded in 1.23 seconds\n",
            "📝 RESPONSE: What are the potential side effects of insulin therapy?...\n",
            "\n",
            "\n",
            "🔍 DEBUG: Preparing request for dr_lee...\n",
            "🔍 DEBUG: Sending request to Azure OpenAI for dr_lee...\n",
            "✅ DEBUG: dr_lee responded in 1.23 seconds\n",
            "📝 RESPONSE: Insulin therapy can cause side effects such as hypoglycemia (low blood sugar), which may lead to sym...\n",
            "\n",
            "\n",
            "🔍 DEBUG: Preparing request for james...\n",
            "🔍 DEBUG: Sending request to Azure OpenAI for james...\n",
            "✅ DEBUG: james responded in 0.44 seconds\n",
            "📝 RESPONSE: What are the risks of long-term uncontrolled blood sugar levels in diabetes?...\n",
            "\n",
            "\n",
            "🔍 DEBUG: Preparing request for dr_smith...\n",
            "🔍 DEBUG: Sending request to Azure OpenAI for dr_smith...\n",
            "✅ DEBUG: dr_smith responded in 1.39 seconds\n",
            "📝 RESPONSE: Long-term uncontrolled blood sugar levels can lead to serious complications. These include cardiovas...\n",
            "\n",
            "\n",
            "🔍 DEBUG: Preparing request for james...\n",
            "🔍 DEBUG: Sending request to Azure OpenAI for james...\n",
            "✅ DEBUG: james responded in 44.13 seconds\n",
            "📝 RESPONSE: What are the common medications used for Type 2 diabetes management?...\n",
            "\n",
            "\n",
            "🔍 DEBUG: Preparing request for dr_lee...\n",
            "🔍 DEBUG: Sending request to Azure OpenAI for dr_lee...\n",
            "✅ DEBUG: dr_lee responded in 4.51 seconds\n",
            "📝 RESPONSE: Common medications for Type 2 diabetes include metformin, which reduces glucose production in the li...\n",
            "\n",
            "✅ DEBUG: Generated 10/25 messages for Diabetes Mellitus...\n",
            "\n",
            "🔍 DEBUG: Preparing request for james...\n",
            "🔍 DEBUG: Sending request to Azure OpenAI for james...\n",
            "✅ DEBUG: james responded in 0.61 seconds\n",
            "📝 RESPONSE: What are the potential side effects of SGLT2 inhibitors in diabetes treatment?...\n",
            "\n",
            "\n",
            "🔍 DEBUG: Preparing request for dr_smith...\n",
            "🔍 DEBUG: Sending request to Azure OpenAI for dr_smith...\n",
            "✅ DEBUG: dr_smith responded in 1.30 seconds\n",
            "📝 RESPONSE: SGLT2 inhibitors can cause side effects such as urinary tract infections and genital yeast infection...\n",
            "\n",
            "\n",
            "🔍 DEBUG: Preparing request for james...\n",
            "🔍 DEBUG: Sending request to Azure OpenAI for james...\n",
            "✅ DEBUG: james responded in 0.46 seconds\n",
            "📝 RESPONSE: What are the symptoms and risks of diabetic ketoacidosis in Type 2 diabetes?...\n",
            "\n",
            "\n",
            "🔍 DEBUG: Preparing request for dr_lee...\n",
            "🔍 DEBUG: Sending request to Azure OpenAI for dr_lee...\n",
            "✅ DEBUG: dr_lee responded in 2.20 seconds\n",
            "📝 RESPONSE: Diabetic ketoacidosis (DKA) in Type 2 diabetes is rare but can occur, especially with SGLT2 inhibito...\n",
            "\n",
            "\n",
            "🔍 DEBUG: Preparing request for james...\n",
            "🔍 DEBUG: Sending request to Azure OpenAI for james...\n",
            "✅ DEBUG: james responded in 0.42 seconds\n",
            "📝 RESPONSE: What are the treatment steps for diabetic ketoacidosis?...\n",
            "\n",
            "\n",
            "🔍 DEBUG: Preparing request for dr_patel...\n",
            "🔍 DEBUG: Sending request to Azure OpenAI for dr_patel...\n",
            "✅ DEBUG: dr_patel responded in 45.27 seconds\n",
            "📝 RESPONSE: Treatment for diabetic ketoacidosis (DKA) involves immediate hospitalization. Key steps include intr...\n",
            "\n",
            "\n",
            "🔍 DEBUG: Preparing request for james...\n",
            "🔍 DEBUG: Sending request to Azure OpenAI for james...\n",
            "✅ DEBUG: james responded in 4.08 seconds\n",
            "📝 RESPONSE: What are the potential complications if diabetic ketoacidosis is not treated promptly?...\n",
            "\n",
            "\n",
            "🔍 DEBUG: Preparing request for dr_smith...\n",
            "🔍 DEBUG: Sending request to Azure OpenAI for dr_smith...\n",
            "✅ DEBUG: dr_smith responded in 1.19 seconds\n",
            "📝 RESPONSE: If diabetic ketoacidosis (DKA) is not treated promptly, it can lead to severe complications, includi...\n",
            "\n",
            "\n",
            "🔍 DEBUG: Preparing request for james...\n",
            "🔍 DEBUG: Sending request to Azure OpenAI for james...\n",
            "✅ DEBUG: james responded in 2.67 seconds\n",
            "📝 RESPONSE: What are the long-term effects of recurrent diabetic ketoacidosis episodes?...\n",
            "\n",
            "\n",
            "🔍 DEBUG: Preparing request for dr_lee...\n",
            "🔍 DEBUG: Sending request to Azure OpenAI for dr_lee...\n",
            "✅ DEBUG: dr_lee responded in 2.06 seconds\n",
            "📝 RESPONSE: Recurrent episodes of diabetic ketoacidosis (DKA) can lead to long-term complications, including chr...\n",
            "\n",
            "✅ DEBUG: Generated 20/25 messages for Diabetes Mellitus...\n",
            "\n",
            "🔍 DEBUG: Preparing request for james...\n",
            "🔍 DEBUG: Sending request to Azure OpenAI for james...\n",
            "✅ DEBUG: james responded in 1.39 seconds\n",
            "📝 RESPONSE: What are the most common triggers for recurrent diabetic ketoacidosis?...\n",
            "\n",
            "\n",
            "🔍 DEBUG: Preparing request for dr_patel...\n",
            "🔍 DEBUG: Sending request to Azure OpenAI for dr_patel...\n",
            "✅ DEBUG: dr_patel responded in 1.27 seconds\n",
            "📝 RESPONSE: The most common triggers for recurrent diabetic ketoacidosis (DKA) include missed or inadequate insu...\n",
            "\n",
            "\n",
            "🔍 DEBUG: Preparing request for james...\n",
            "🔍 DEBUG: Sending request to Azure OpenAI for james...\n",
            "✅ DEBUG: james responded in 39.70 seconds\n",
            "📝 RESPONSE: What are the warning signs that diabetic ketoacidosis might be developing?...\n",
            "\n",
            "\n",
            "🔍 DEBUG: Preparing request for dr_smith...\n",
            "🔍 DEBUG: Sending request to Azure OpenAI for dr_smith...\n",
            "✅ DEBUG: dr_smith responded in 5.80 seconds\n",
            "📝 RESPONSE: The warning signs of diabetic ketoacidosis (DKA) include excessive thirst, frequent urination, and s...\n",
            "\n",
            "\n",
            "🔍 DEBUG: Preparing request for james...\n",
            "🔍 DEBUG: Sending request to Azure OpenAI for james...\n",
            "✅ DEBUG: james responded in 0.44 seconds\n",
            "📝 RESPONSE: What are the long-term risks if diabetic ketoacidosis occurs repeatedly?...\n",
            "\n",
            "\n",
            "🔍 DEBUG: Preparing request for james...\n",
            "🔍 DEBUG: Sending request to Azure OpenAI for james...\n",
            "✅ DEBUG: james responded in 0.70 seconds\n",
            "📝 RESPONSE: What are the common symptoms of hypertension?...\n",
            "\n",
            "\n",
            "🔍 DEBUG: Preparing request for dr_smith...\n",
            "🔍 DEBUG: Sending request to Azure OpenAI for dr_smith...\n",
            "✅ DEBUG: dr_smith responded in 4.19 seconds\n",
            "📝 RESPONSE: Hypertension is often called the \"silent killer\" because it typically has no noticeable symptoms. Ho...\n",
            "\n",
            "\n",
            "🔍 DEBUG: Preparing request for james...\n",
            "🔍 DEBUG: Sending request to Azure OpenAI for james...\n",
            "✅ DEBUG: james responded in 1.08 seconds\n",
            "📝 RESPONSE: What are the main treatment options for hypertension?...\n",
            "\n",
            "\n",
            "🔍 DEBUG: Preparing request for dr_lee...\n",
            "🔍 DEBUG: Sending request to Azure OpenAI for dr_lee...\n",
            "✅ DEBUG: dr_lee responded in 1.42 seconds\n",
            "📝 RESPONSE: Hypertension treatment typically involves lifestyle modifications and, if necessary, medications. Li...\n",
            "\n",
            "\n",
            "🔍 DEBUG: Preparing request for james...\n",
            "🔍 DEBUG: Sending request to Azure OpenAI for james...\n",
            "✅ DEBUG: james responded in 0.99 seconds\n",
            "📝 RESPONSE: What are the potential side effects of hypertension medications?...\n",
            "\n",
            "\n",
            "🔍 DEBUG: Preparing request for dr_lee...\n",
            "🔍 DEBUG: Sending request to Azure OpenAI for dr_lee...\n",
            "✅ DEBUG: dr_lee responded in 38.66 seconds\n",
            "📝 RESPONSE: Hypertension medications can cause various side effects depending on the class. ACE inhibitors may l...\n",
            "\n",
            "\n",
            "🔍 DEBUG: Preparing request for james...\n",
            "🔍 DEBUG: Sending request to Azure OpenAI for james...\n",
            "✅ DEBUG: james responded in 2.52 seconds\n",
            "📝 RESPONSE: What happens if hypertension is left untreated?...\n",
            "\n",
            "\n",
            "🔍 DEBUG: Preparing request for dr_smith...\n",
            "🔍 DEBUG: Sending request to Azure OpenAI for dr_smith...\n",
            "✅ DEBUG: dr_smith responded in 4.36 seconds\n",
            "📝 RESPONSE: Untreated hypertension can lead to severe complications over time. It increases the risk of heart di...\n",
            "\n",
            "\n",
            "🔍 DEBUG: Preparing request for james...\n",
            "🔍 DEBUG: Sending request to Azure OpenAI for james...\n",
            "✅ DEBUG: james responded in 0.53 seconds\n",
            "📝 RESPONSE: How does hypertension damage the kidneys?...\n",
            "\n",
            "\n",
            "🔍 DEBUG: Preparing request for dr_lee...\n",
            "🔍 DEBUG: Sending request to Azure OpenAI for dr_lee...\n",
            "✅ DEBUG: dr_lee responded in 7.80 seconds\n",
            "📝 RESPONSE: Hypertension damages the kidneys by exerting excessive pressure on the delicate blood vessels within...\n",
            "\n",
            "✅ DEBUG: Generated 10/25 messages for Hypertension...\n",
            "\n",
            "🔍 DEBUG: Preparing request for james...\n",
            "🔍 DEBUG: Sending request to Azure OpenAI for james...\n",
            "✅ DEBUG: james responded in 0.42 seconds\n",
            "📝 RESPONSE: What are the symptoms of kidney damage caused by hypertension?...\n",
            "\n",
            "\n",
            "🔍 DEBUG: Preparing request for dr_smith...\n",
            "🔍 DEBUG: Sending request to Azure OpenAI for dr_smith...\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-9f263b984aaf>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     80\u001b[0m             \u001b[0mcurrent_speaker\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchoice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Dr. Smith\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Dr. Patel\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Dr. Lee\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 82\u001b[0;31m         \u001b[0mnew_message\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerate_message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcurrent_speaker\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconversation_history\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     83\u001b[0m         \u001b[0mconversation_history\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_message\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m         \u001b[0mgenerated_messages\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-6-9f263b984aaf>\u001b[0m in \u001b[0;36mgenerate_message\u001b[0;34m(speaker, history)\u001b[0m\n\u001b[1;32m     47\u001b[0m           \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"🔍 DEBUG: Sending request to Azure OpenAI for {sanitized_speaker}...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m           response = llm([\n\u001b[0m\u001b[1;32m     50\u001b[0m               \u001b[0mSystemMessage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msystem_prompt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"system\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m               *[\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langchain_core/_api/deprecation.py\u001b[0m in \u001b[0;36mwarning_emitting_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    179\u001b[0m                 \u001b[0mwarned\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m                 \u001b[0memit_warning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 181\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    182\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    183\u001b[0m         \u001b[0;32masync\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mawarning_emitting_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langchain_core/language_models/chat_models.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, messages, stop, callbacks, **kwargs)\u001b[0m\n\u001b[1;32m   1089\u001b[0m         \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1090\u001b[0m     ) -> BaseMessage:\n\u001b[0;32m-> 1091\u001b[0;31m         generation = self.generate(\n\u001b[0m\u001b[1;32m   1092\u001b[0m             \u001b[0;34m[\u001b[0m\u001b[0mmessages\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1093\u001b[0m         ).generations[0][0]\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langchain_core/language_models/chat_models.py\u001b[0m in \u001b[0;36mgenerate\u001b[0;34m(self, messages, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001b[0m\n\u001b[1;32m    688\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    689\u001b[0m                 results.append(\n\u001b[0;32m--> 690\u001b[0;31m                     self._generate_with_cache(\n\u001b[0m\u001b[1;32m    691\u001b[0m                         \u001b[0mm\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    692\u001b[0m                         \u001b[0mstop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langchain_core/language_models/chat_models.py\u001b[0m in \u001b[0;36m_generate_with_cache\u001b[0;34m(self, messages, stop, run_manager, **kwargs)\u001b[0m\n\u001b[1;32m    923\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    924\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0minspect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_generate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"run_manager\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 925\u001b[0;31m                 result = self._generate(\n\u001b[0m\u001b[1;32m    926\u001b[0m                     \u001b[0mmessages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrun_manager\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    927\u001b[0m                 )\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langchain_openai/chat_models/base.py\u001b[0m in \u001b[0;36m_generate\u001b[0;34m(self, messages, stop, run_manager, **kwargs)\u001b[0m\n\u001b[1;32m    798\u001b[0m             \u001b[0mgeneration_info\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\"headers\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mraw_response\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mheaders\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    799\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 800\u001b[0;31m             \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclient\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mpayload\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    801\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_chat_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgeneration_info\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    802\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/openai/_utils/_utils.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    277\u001b[0m                         \u001b[0mmsg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf\"Missing required argument: {quote(missing[0])}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    278\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 279\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    280\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    281\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m  \u001b[0;31m# type: ignore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/openai/resources/chat/completions.py\u001b[0m in \u001b[0;36mcreate\u001b[0;34m(self, messages, model, audio, frequency_penalty, function_call, functions, logit_bias, logprobs, max_completion_tokens, max_tokens, metadata, modalities, n, parallel_tool_calls, prediction, presence_penalty, reasoning_effort, response_format, seed, service_tier, stop, store, stream, stream_options, temperature, tool_choice, tools, top_logprobs, top_p, user, extra_headers, extra_query, extra_body, timeout)\u001b[0m\n\u001b[1;32m    861\u001b[0m     ) -> ChatCompletion | Stream[ChatCompletionChunk]:\n\u001b[1;32m    862\u001b[0m         \u001b[0mvalidate_response_format\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse_format\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 863\u001b[0;31m         return self._post(\n\u001b[0m\u001b[1;32m    864\u001b[0m             \u001b[0;34m\"/chat/completions\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    865\u001b[0m             body=maybe_transform(\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/openai/_base_client.py\u001b[0m in \u001b[0;36mpost\u001b[0;34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1281\u001b[0m             \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"post\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjson_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mto_httpx_files\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiles\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1282\u001b[0m         )\n\u001b[0;32m-> 1283\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mResponseT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcast_to\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream_cls\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstream_cls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1284\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1285\u001b[0m     def patch(\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/openai/_base_client.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[1;32m    958\u001b[0m             \u001b[0mretries_taken\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    959\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 960\u001b[0;31m         return self._request(\n\u001b[0m\u001b[1;32m    961\u001b[0m             \u001b[0mcast_to\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcast_to\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    962\u001b[0m             \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/openai/_base_client.py\u001b[0m in \u001b[0;36m_request\u001b[0;34m(self, cast_to, options, retries_taken, stream, stream_cls)\u001b[0m\n\u001b[1;32m    994\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    995\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 996\u001b[0;31m             response = self._client.send(\n\u001b[0m\u001b[1;32m    997\u001b[0m                 \u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    998\u001b[0m                 \u001b[0mstream\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstream\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_should_stream_response_body\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/httpx/_client.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, stream, auth, follow_redirects)\u001b[0m\n\u001b[1;32m    912\u001b[0m         \u001b[0mauth\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_build_request_auth\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mauth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    913\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 914\u001b[0;31m         response = self._send_handling_auth(\n\u001b[0m\u001b[1;32m    915\u001b[0m             \u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    916\u001b[0m             \u001b[0mauth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mauth\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/httpx/_client.py\u001b[0m in \u001b[0;36m_send_handling_auth\u001b[0;34m(self, request, auth, follow_redirects, history)\u001b[0m\n\u001b[1;32m    940\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    941\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 942\u001b[0;31m                 response = self._send_handling_redirects(\n\u001b[0m\u001b[1;32m    943\u001b[0m                     \u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    944\u001b[0m                     \u001b[0mfollow_redirects\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfollow_redirects\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/httpx/_client.py\u001b[0m in \u001b[0;36m_send_handling_redirects\u001b[0;34m(self, request, follow_redirects, history)\u001b[0m\n\u001b[1;32m    977\u001b[0m                 \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    978\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 979\u001b[0;31m             \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_send_single_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    980\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    981\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_event_hooks\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"response\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/httpx/_client.py\u001b[0m in \u001b[0;36m_send_single_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m   1012\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1013\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mrequest_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1014\u001b[0;31m             \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransport\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1015\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1016\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSyncByteStream\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/httpx/_transports/default.py\u001b[0m in \u001b[0;36mhandle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    248\u001b[0m         )\n\u001b[1;32m    249\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mmap_httpcore_exceptions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 250\u001b[0;31m             \u001b[0mresp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pool\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    251\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    252\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtyping\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/httpcore/_sync/connection_pool.py\u001b[0m in \u001b[0;36mhandle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    254\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_close_connections\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclosing\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 256\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mexc\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    257\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    258\u001b[0m         \u001b[0;31m# Return the response. Note that in this case we still have to manage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/httpcore/_sync/connection_pool.py\u001b[0m in \u001b[0;36mhandle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    234\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    235\u001b[0m                     \u001b[0;31m# Send the request on the assigned connection.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 236\u001b[0;31m                     response = connection.handle_request(\n\u001b[0m\u001b[1;32m    237\u001b[0m                         \u001b[0mpool_request\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    238\u001b[0m                     )\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/httpcore/_sync/connection.py\u001b[0m in \u001b[0;36mhandle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    101\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_connection\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_connect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mRequest\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mNetworkStream\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/httpcore/_sync/http11.py\u001b[0m in \u001b[0;36mhandle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    134\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"response_closed\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogger\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_response_closed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 136\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    137\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m     \u001b[0;31m# Sending the request...\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/httpcore/_sync/http11.py\u001b[0m in \u001b[0;36mhandle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    104\u001b[0m                     \u001b[0mheaders\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m                     \u001b[0mtrailing_data\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 106\u001b[0;31m                 ) = self._receive_response_headers(**kwargs)\n\u001b[0m\u001b[1;32m    107\u001b[0m                 trace.return_value = (\n\u001b[1;32m    108\u001b[0m                     \u001b[0mhttp_version\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/httpcore/_sync/http11.py\u001b[0m in \u001b[0;36m_receive_response_headers\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    175\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    176\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 177\u001b[0;31m             \u001b[0mevent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_receive_event\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    178\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh11\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mResponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/httpcore/_sync/http11.py\u001b[0m in \u001b[0;36m_receive_event\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mevent\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mh11\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNEED_DATA\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 217\u001b[0;31m                 data = self._network_stream.read(\n\u001b[0m\u001b[1;32m    218\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mREAD_NUM_BYTES\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m                 )\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/httpcore/_backends/sync.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, max_bytes, timeout)\u001b[0m\n\u001b[1;32m    126\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mmap_exceptions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexc_map\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msettimeout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 128\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_bytes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbytes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mfloat\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/ssl.py\u001b[0m in \u001b[0;36mrecv\u001b[0;34m(self, buflen, flags)\u001b[0m\n\u001b[1;32m   1293\u001b[0m                     \u001b[0;34m\"non-zero flags not allowed in calls to recv() on %s\"\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1294\u001b[0m                     self.__class__)\n\u001b[0;32m-> 1295\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuflen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1296\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1297\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuflen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/ssl.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, len, buffer)\u001b[0m\n\u001b[1;32m   1166\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1167\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1168\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1169\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mSSLError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1170\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mSSL_ERROR_EOF\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msuppress_ragged_eofs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "\n",
        "file_path = \"/content/large_chat_dataset.json\"\n",
        "\n",
        "with open(file_path, \"r\") as f:\n",
        "    chat_data = json.load(f)\n",
        "\n",
        "\n",
        "documents = []\n",
        "metadata = []\n",
        "\n",
        "for entry in chat_data:\n",
        "    disease = entry[\"disease\"]\n",
        "    for chat in entry[\"chat\"]:\n",
        "        text = chat[\"message\"]\n",
        "        speaker = chat[\"speaker\"]\n",
        "        timestamp = chat[\"timestamp\"]\n",
        "\n",
        "\n",
        "        doc = f\"Disease: {disease}\\nSpeaker: {speaker}\\nMessage: {text}\"\n",
        "        documents.append(doc)\n",
        "\n",
        "\n",
        "        metadata.append({\"disease\": disease, \"speaker\": speaker, \"timestamp\": timestamp})\n",
        "\n",
        "\n",
        "print(f\"✅ Processed {len(documents)} chat messages.\")\n",
        "print(\"🔍 Sample Document:\\n\", documents[3])\n"
      ],
      "metadata": {
        "id": "SBuV-4zUj5E8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q openai==0.28"
      ],
      "metadata": {
        "id": "FisdZWUBkxqh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import openai\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "\n",
        "openai.api_key = api_key\n",
        "\n",
        "\n",
        "def get_embedding(text):\n",
        "    response = openai.Embedding.create(\n",
        "        input=text,\n",
        "        model=\"text-embedding-ada-002\"\n",
        "    )\n",
        "    return response[\"data\"][0][\"embedding\"]\n",
        "\n",
        "\n",
        "embeddings = []\n",
        "for doc in documents:\n",
        "    embedding = get_embedding(doc)\n",
        "    embeddings.append(embedding)\n",
        "\n",
        "\n",
        "embeddings = np.array(embeddings, dtype=np.float32)\n",
        "\n",
        "\n",
        "print(f\"✅ Generated {len(embeddings)} embeddings.\")\n",
        "print(\"🔍 Sample embedding:\\n\", embeddings[0][:5])\n"
      ],
      "metadata": {
        "id": "5HsDsX8SkSea"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import faiss\n",
        "\n",
        "embedding_dim = 1536\n",
        "\n",
        "index = faiss.IndexFlatL2(embedding_dim)\n",
        "index.add(embeddings)\n",
        "\n",
        "faiss.write_index(index, \"faiss_chat_index\")\n",
        "\n",
        "with open(\"metadata.json\", \"w\") as f:\n",
        "    json.dump(metadata, f, indent=4)\n",
        "\n",
        "print(\"✅ FAISS index and metadata saved successfully.\")\n"
      ],
      "metadata": {
        "id": "qtAO8Ybol2m2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import openai\n",
        "import numpy as np\n",
        "\n",
        "file_path = \"/content/large_chat_dataset.json\"\n",
        "\n",
        "with open(file_path, \"r\") as f:\n",
        "    chat_data = json.load(f)\n",
        "\n",
        "documents = []\n",
        "metadata = []\n",
        "\n",
        "for entry in chat_data:\n",
        "    disease = entry[\"disease\"]\n",
        "    for chat in entry[\"chat\"]:\n",
        "        text = chat[\"message\"]\n",
        "        speaker = chat[\"speaker\"]\n",
        "        timestamp = chat[\"timestamp\"]\n",
        "\n",
        "\n",
        "        doc = f\"Disease: {disease}\\nSpeaker: {speaker}\\nMessage: {text}\"\n",
        "        documents.append(doc)\n",
        "\n",
        "\n",
        "        metadata.append({\"disease\": disease, \"speaker\": speaker, \"timestamp\": timestamp})\n",
        "\n",
        "with open(\"chat_texts.json\", \"w\") as f:\n",
        "    json.dump(documents, f, indent=4)\n",
        "\n",
        "with open(\"metadata.json\", \"w\") as f:\n",
        "    json.dump(metadata, f, indent=4)\n",
        "\n",
        "print(f\"✅ Saved {len(documents)} chat messages to 'chat_texts.json'.\")\n"
      ],
      "metadata": {
        "id": "3hFnhFkhnOMy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import faiss\n",
        "import openai\n",
        "import numpy as np\n",
        "import json\n",
        "\n",
        "\n",
        "index = faiss.read_index(\"faiss_chat_index\")\n",
        "\n",
        "# Load metadata\n",
        "with open(\"metadata.json\", \"r\") as f:\n",
        "    metadata = json.load(f)\n",
        "\n",
        "\n",
        "with open(\"chat_texts.json\", \"r\") as f:\n",
        "    documents = json.load(f)\n",
        "\n",
        "\n",
        "def get_embedding(text):\n",
        "    response = openai.Embedding.create(\n",
        "        input=text,\n",
        "        model=\"text-embedding-ada-002\"\n",
        "    )\n",
        "    return np.array(response[\"data\"][0][\"embedding\"], dtype=np.float32)\n",
        "\n",
        "\n",
        "def retrieve_similar_chats(query, top_k=4):\n",
        "    query_embedding = get_embedding(query).reshape(1, -1)\n",
        "    distances, indices = index.search(query_embedding, top_k)\n",
        "\n",
        "\n",
        "    retrieved_docs = []\n",
        "    for idx in indices[0]:\n",
        "        if idx < len(metadata):\n",
        "            doc_data = metadata[idx].copy()\n",
        "            doc_data[\"message\"] = documents[idx]\n",
        "            retrieved_docs.append(doc_data)\n",
        "\n",
        "    return retrieved_docs\n",
        "\n",
        "\n",
        "query = \"What is cholinesterase?\"\n",
        "retrieved_messages = retrieve_similar_chats(query)\n",
        "\n",
        "\n",
        "print(\"\\n🔍 Top Retrieved Messages:\")\n",
        "for msg in retrieved_messages:\n",
        "    print(f\"📌 Disease: {msg['disease']} | 🩺 Speaker: {msg['speaker']}\")\n",
        "    print(f\"🕒 Timestamp: {msg['timestamp']}\")\n",
        "    print(f\"💬 Message: {msg['message']}\\n\")\n"
      ],
      "metadata": {
        "id": "QtiskEszmHrE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import faiss\n",
        "import openai\n",
        "import numpy as np\n",
        "import json\n",
        "\n",
        "\n",
        "index = faiss.read_index(\"faiss_chat_index\")\n",
        "\n",
        "with open(\"metadata.json\", \"r\") as f:\n",
        "    metadata = json.load(f)\n",
        "\n",
        "with open(\"chat_texts.json\", \"r\") as f:\n",
        "    documents = json.load(f)\n",
        "\n",
        "openai.api_key = api_key\n",
        "\n",
        "def get_embedding(text):\n",
        "    response = openai.Embedding.create(\n",
        "        input=text,\n",
        "        model=\"text-embedding-ada-002\"\n",
        "    )\n",
        "    return np.array(response[\"data\"][0][\"embedding\"], dtype=np.float32)\n",
        "\n",
        "def retrieve_similar_chats(query, top_k=5):\n",
        "    query_embedding = get_embedding(query).reshape(1, -1)\n",
        "    distances, indices = index.search(query_embedding, top_k)\n",
        "\n",
        "\n",
        "    retrieved_docs = []\n",
        "    for idx in indices[0]:\n",
        "        if idx < len(metadata):\n",
        "            doc_data = metadata[idx].copy()\n",
        "            doc_data[\"message\"] = documents[idx]\n",
        "            retrieved_docs.append(doc_data)\n",
        "\n",
        "    return retrieved_docs\n",
        "\n",
        "\n",
        "def generate_response(user_query):\n",
        "\n",
        "    retrieved_messages = retrieve_similar_chats(user_query)\n",
        "\n",
        "\n",
        "    context = \"\\n\".join([f\"{msg['speaker']}: {msg['message']}\" for msg in retrieved_messages])\n",
        "\n",
        "\n",
        "    system_prompt = (\n",
        "    \"You are a medical chatbot that provides informative, well-structured, and accurate answers based solely on the information available in the chat history. \"\n",
        "    \"Do not introduce any external knowledge, and refrain from speculating or providing information that has not been mentioned in the conversation. \"\n",
        "    \"If a user says they have a certain symptom , you must look into your dataset to see if you know what can be the possible cause, say CLEAR no if you have no idea, and suggest to consult a doctor either way!\"\n",
        "    \"If a question arises that is not covered within the chat history, your response should be clear and direct: 'This information is not mentioned in the chat.' \"\n",
        "    \"You should always use the context and background from previous messages to generate your responses, ensuring relevance and clarity, but avoid repeating messages verbatim. \"\n",
        "    \"Maintain a helpful and educational tone, providing concise and precise answers based only on the provided conversation.\"\n",
        ")\n",
        "\n",
        "\n",
        "    response = openai.ChatCompletion.create(\n",
        "        model=\"gpt-4o\",\n",
        "        messages=[\n",
        "            {\"role\": \"system\", \"content\": system_prompt},\n",
        "            {\"role\": \"user\", \"content\": f\"User Question: {user_query}\\n\\nRetrieved Context:\\n{context}\"}\n",
        "        ]\n",
        "    )\n",
        "\n",
        "    return response[\"choices\"][0][\"message\"][\"content\"]\n",
        "\n",
        "\n",
        "print(\"🩺 Medical Chatbot (Type 'exit' to quit)\\n\")\n",
        "while True:\n",
        "    user_query = input(\"You: \")\n",
        "    if user_query.lower() == \"exit\":\n",
        "        print(\"👋 Goodbye!\")\n",
        "        break\n",
        "\n",
        "    bot_response = generate_response(user_query)\n",
        "    print(f\"💬 Chatbot: {bot_response}\\n\")\n"
      ],
      "metadata": {
        "id": "tFjQAsLGod8z"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}